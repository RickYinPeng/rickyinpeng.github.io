<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hadoop," />










<meta name="description" content="Kafka APIProducer API消息发送流程Kafka的Producer发送消息采用的是异步发送的方式。在消息发送的过程中，涉及到了两个线程——main线程和Sender线程，以及一个线程共享变量——RecordAccumulator。main线程将消息发送给RecordAccumulator，Sender线程不断从RecordAccumulator中拉取消息发送到Kafka broke">
<meta name="keywords" content="Hadoop">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka基础学习-三之kafkaAPI、flume对接kafka、kafka监控">
<meta property="og:url" content="http://yoursite.com/2020/02/08/kafka基础学习-三之Kafka API/index.html">
<meta property="og:site_name" content="RickYinPeng&#39;s blog">
<meta property="og:description" content="Kafka APIProducer API消息发送流程Kafka的Producer发送消息采用的是异步发送的方式。在消息发送的过程中，涉及到了两个线程——main线程和Sender线程，以及一个线程共享变量——RecordAccumulator。main线程将消息发送给RecordAccumulator，Sender线程不断从RecordAccumulator中拉取消息发送到Kafka broke">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://p.caigoubao.cc/606599/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/5_132253494855091250.png">
<meta property="og:image" content="http://p.caigoubao.cc/606599/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/7_132254508869153750.png">
<meta property="og:image" content="http://p.caigoubao.cc/606599/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/8_132256059758060000.png">
<meta property="og:updated_time" content="2020-02-08T03:35:23.726Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="kafka基础学习-三之kafkaAPI、flume对接kafka、kafka监控">
<meta name="twitter:description" content="Kafka APIProducer API消息发送流程Kafka的Producer发送消息采用的是异步发送的方式。在消息发送的过程中，涉及到了两个线程——main线程和Sender线程，以及一个线程共享变量——RecordAccumulator。main线程将消息发送给RecordAccumulator，Sender线程不断从RecordAccumulator中拉取消息发送到Kafka broke">
<meta name="twitter:image" content="http://p.caigoubao.cc/606599/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/5_132253494855091250.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"hide","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/02/08/kafka基础学习-三之Kafka API/"/>





  <title>kafka基础学习-三之kafkaAPI、flume对接kafka、kafka监控 | RickYinPeng's blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
	<a href="https://github.com/RickYinPeng"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"></a>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">RickYinPeng's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-search">
          <a href="/search" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            搜索
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/08/kafka基础学习-三之Kafka API/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="RickYinPeng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/We.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RickYinPeng's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">kafka基础学习-三之kafkaAPI、flume对接kafka、kafka监控</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-02-08T11:34:20+08:00">
                2020-02-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="Kafka-API"><a href="#Kafka-API" class="headerlink" title="Kafka API"></a>Kafka API</h2><h3 id="Producer-API"><a href="#Producer-API" class="headerlink" title="Producer API"></a>Producer API</h3><h4 id="消息发送流程"><a href="#消息发送流程" class="headerlink" title="消息发送流程"></a>消息发送流程</h4><p>Kafka的Producer发送消息采用的是<font size="3" color="red">异步发送</font>的方式。在消息发送的过程中，涉及到了两个线程——<font size="3" color="red">main线程</font>和<font size="3" color="red">Sender线程</font>，以及一个<font size="3" color="red">线程共享变量</font>——<font size="3" color="red">RecordAccumulator</font>。main线程将消息发送给RecordAccumulator，Sender线程不断从RecordAccumulator中拉取消息发送到Kafka broker。</p>
<p><img src="http://p.caigoubao.cc/606599/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/5_132253494855091250.png" alt="image"></p>
<blockquote>
<p>相关参数：<br>batch.size：只有数据积累到batch.size之后，sender才会发送数据。<br>linger.ms：如果数据迟迟未达到batch.size，sender等待linger.time之后就会发送数据。</p>
</blockquote>
<h4 id="异步发送API"><a href="#异步发送API" class="headerlink" title="异步发送API"></a>异步发送API</h4><h5 id="导入依赖"><a href="#导入依赖" class="headerlink" title="导入依赖"></a>导入依赖</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;0.11.0.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>
<h5 id="编写代码"><a href="#编写代码" class="headerlink" title="编写代码"></a>编写代码</h5><p>需要用到的类：</p>
<ul>
<li>KafkaProducer：需要创建一个生产者对象，用来发送数据</li>
<li>ProducerConfig：获取所需的一系列配置参数</li>
<li>ProducerRecord：每条数据都要封装成一个ProducerRecord对象</li>
</ul>
<h6 id="不带回调函数的API"><a href="#不带回调函数的API" class="headerlink" title="不带回调函数的API"></a>不带回调函数的API</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">package com.rickyin.kafka.producer;</span><br><span class="line"></span><br><span class="line">import org.apache.kafka.clients.producer.*;</span><br><span class="line">import org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line">import java.util.Properties;</span><br><span class="line"></span><br><span class="line">public class ProducerCallBack &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        Properties properties = new Properties();</span><br><span class="line">        //设置brokeList（回顾命令行）</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;hadoop102:9092&quot;);</span><br><span class="line">        //设置key和value的序列化</span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        //设置ack</span><br><span class="line">        properties.put(ProducerConfig.ACKS_CONFIG, &quot;all&quot;);</span><br><span class="line">        //设置一次读取多少数据（一批一批的数据）</span><br><span class="line">        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);</span><br><span class="line">        //设置1ms</span><br><span class="line">        properties.put(ProducerConfig.LINGER_MS_CONFIG, 1);</span><br><span class="line"></span><br><span class="line">        //1.创建一个生产者对象</span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        //2.调用send方法</span><br><span class="line">        for (int i = 0; i &lt; 1000; i++) &#123;</span><br><span class="line">            producer.send(new ProducerRecord&lt;String, String&gt;(&quot;first&quot;, i + &quot;&quot;,&quot;message-&quot; + i)&#125;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        //3.关闭生产者</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h6 id="带回调函数的API"><a href="#带回调函数的API" class="headerlink" title="带回调函数的API"></a>带回调函数的API</h6><p>回调函数会在producer收到ack时调用，为异步调用，该方法有两个参数，分别是RecordMetadata和Exception，如果Exception为null，说明消息发送成功，如果Exception不为null，说明消息发送失败。</p>
<blockquote>
<font size="3" color="red">注意：消息发送失败会自动重试，不需要我们在回调函数中手动重试。</font>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">package com.rickyin.kafka.producer;</span><br><span class="line"></span><br><span class="line">import org.apache.kafka.clients.producer.*;</span><br><span class="line">import org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line">import java.util.Properties;</span><br><span class="line"></span><br><span class="line">public class ProducerCallBack &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        Properties properties = new Properties();</span><br><span class="line">        //设置brokeList（回顾命令行）</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;hadoop102:9092&quot;);</span><br><span class="line">        //设置key和value的序列化</span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        //设置ack</span><br><span class="line">        properties.put(ProducerConfig.ACKS_CONFIG, &quot;all&quot;);</span><br><span class="line">        //设置一次读取多少数据（一批一批的数据）</span><br><span class="line">        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);</span><br><span class="line">        //设置1ms</span><br><span class="line">        properties.put(ProducerConfig.LINGER_MS_CONFIG, 1);</span><br><span class="line"></span><br><span class="line">        //1.创建一个生产者对象</span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        //2.调用send方法</span><br><span class="line">        for (int i = 0; i &lt; 1000; i++) &#123;</span><br><span class="line">            producer.send(new ProducerRecord&lt;String, String&gt;(&quot;first&quot;, i + &quot;&quot;, &quot;message-&quot; + i), (recordMetadata, exception) -&gt; &#123;</span><br><span class="line">                if (exception == null) &#123;</span><br><span class="line">                    System.out.println(&quot;success&quot;);</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    exception.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        //3.关闭生产者</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="同步发送API"><a href="#同步发送API" class="headerlink" title="同步发送API"></a>同步发送API</h4><p>同步发送的意思就是，一条消息发送之后，会阻塞当前线程，直至返回ack。<br>由于send方法返回的是一个Future对象，<font size="3" color="red">根据Futrue对象的特点</font>，我们也可以实现同步发送的效果，只需在<font size="3" color="red">调用Future对象的get</font>方发即可。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.rickyin.kafka.producer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.RecordMetadata;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutionException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SyncProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">//设置brokeList（回顾命令行）</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"hadoop102:9092"</span>);</span><br><span class="line">        <span class="comment">//设置key和value的序列化</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        <span class="comment">//设置ack</span></span><br><span class="line">        properties.put(ProducerConfig.ACKS_CONFIG, <span class="string">"all"</span>);</span><br><span class="line">        <span class="comment">//设置一次读取多少数据（一批一批的数据）</span></span><br><span class="line">        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">16384</span>);</span><br><span class="line">        <span class="comment">//设置1ms</span></span><br><span class="line">        properties.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.创建一个生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.调用send方法</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++) &#123;</span><br><span class="line">            <span class="comment">//调用get方法，阻塞线程</span></span><br><span class="line">            RecordMetadata recordMetadata = producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"first"</span>, i + <span class="string">""</span>, <span class="string">"message-"</span> + i)).get();</span><br><span class="line">            System.out.println(<span class="string">"offset:"</span> + recordMetadata.offset());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.关闭生产者</span></span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Consumer-API"><a href="#Consumer-API" class="headerlink" title="Consumer API"></a>Consumer API</h3><p>Consumer消费数据时的可靠性是很容易保证的，因为数据在Kafka中是持久化的，故不用担心数据丢失问题。<br><br>由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。<br><br>所以offset的维护是Consumer消费数据是必须考虑的问题。<br></p>
<h4 id="手动提交offset"><a href="#手动提交offset" class="headerlink" title="手动提交offset"></a>手动提交offset</h4><h5 id="导入依赖-1"><a href="#导入依赖-1" class="headerlink" title="导入依赖"></a>导入依赖</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;0.11.0.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>
<h5 id="编写代码-1"><a href="#编写代码-1" class="headerlink" title="编写代码"></a>编写代码</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.rickyin.kafka.consume;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomConsume</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"hadoop102:9092"</span>);</span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"1"</span>);<span class="comment">//消费者组，只要group.id相同，就属于同一个消费者组</span></span><br><span class="line">        <span class="comment">//自动提交offset默认是开启的，我们在这里将其关闭，为了测试异步提交offset和同步提交offset</span></span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,<span class="string">"false"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.创建一个消费者</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定消费哪个topic</span></span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">"first"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.调用poll方法</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(<span class="number">100</span>);</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(<span class="string">"topic:"</span> + consumerRecord.topic() + <span class="string">" partition:"</span> + consumerRecord.partition() + <span class="string">" offset:"</span> + consumerRecord.offset() + <span class="string">" value:"</span> + consumerRecord.value());</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">//1.同步提,有重试机制</span></span><br><span class="line">            consumer.commitSync();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">//2.异步提交，没有失败重试机制</span></span><br><span class="line">            <span class="comment">//consumer.commitAsync();</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h5><p>手动提交offset的方法有两种：分别是commitSync（同步提交）和commitAsync（异步提交）。两者的相同点是，都会将本次poll的一批数据最高的偏移量提交；不同点是，commitSync会失败重试，一直到提交成功（如果由于不可恢复原因导致，也会提交失败）；而commitAsync则没有失败重试机制，故有可能提交失败。</p>
<h5 id="数据重复消费问题"><a href="#数据重复消费问题" class="headerlink" title="数据重复消费问题"></a>数据重复消费问题</h5><p><img src="http://p.caigoubao.cc/606599/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/7_132254508869153750.png" alt="image"></p>
<h4 id="自动提交offset"><a href="#自动提交offset" class="headerlink" title="自动提交offset"></a>自动提交offset</h4><p>为了使我们能够专注于自己的业务逻辑，Kafka提供了自动提交offset的功能。 <br><br>自动提交offset的相关参数：</p>
<ul>
<li>enable.auto.commit：是否开启自动提交offset功能</li>
<li>auto.commit.interval.ms：自动提交offset的时间间隔</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">package com.atguigu.kafka;</span><br><span class="line"></span><br><span class="line">import org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line">import org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line">import org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"></span><br><span class="line">import java.util.Arrays;</span><br><span class="line">import java.util.Properties;</span><br><span class="line"></span><br><span class="line">public class CustomConsumer &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        Properties props = new Properties();</span><br><span class="line">        props.put(&quot;bootstrap.servers&quot;, &quot;hadoop102:9092&quot;);</span><br><span class="line">        props.put(&quot;group.id&quot;, &quot;test&quot;);</span><br><span class="line">        props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);</span><br><span class="line">        props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);</span><br><span class="line">        props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span><br><span class="line">        props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);</span><br><span class="line">        consumer.subscribe(Arrays.asList(&quot;first&quot;));</span><br><span class="line">        while (true) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);</span><br><span class="line">            for (ConsumerRecord&lt;String, String&gt; record : records)</span><br><span class="line">                System.out.printf(&quot;offset = %d, key = %s, value = %s%n&quot;, record.offset(), record.key(), record.value());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="自定义Interceptor"><a href="#自定义Interceptor" class="headerlink" title="自定义Interceptor"></a>自定义Interceptor</h3><h4 id="拦截器原理"><a href="#拦截器原理" class="headerlink" title="拦截器原理"></a>拦截器原理</h4><p>Producer拦截器(interceptor)是在Kafka 0.10版本被引入的，主要用于实现clients端的定制化控制逻辑。</p>
<p>对于producer而言，interceptor使得用户在消息发送前以及producer回调逻辑前有机会对消息做一些定制化需求，比如修改消息等。同时，producer允许用户指定多个interceptor按序作用于同一条消息从而形成一个拦截链(interceptor chain)。Intercetpor的实现接口是<font size="3" color="red">org.apache.kafka.clients.producer.ProducerInterceptor</font>，其定义的方法包括：</p>
<ul>
<li><p>configure(configs)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">获取配置信息和初始化数据时调用。</span><br></pre></td></tr></table></figure>
</li>
<li><p>onSend(ProducerRecord)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">该方法封装进KafkaProducer.send方法中，即它运行在用户主线程中。Producer确保在消息被序列化以及计算分区前调用该方法。用户可以在该方法中对消息做任何操作，但最好保证不要修改消息所属的topic和分区，否则会影响目标分区的计算。</span><br></pre></td></tr></table></figure>
</li>
<li><p>onAcknowledgement(RecordMetadata, Exception)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">该方法会在消息从RecordAccumulator成功发送到Kafka Broker之后，或者在发送过程中失败时调用。并且通常都是在producer回调逻辑触发之前。onAcknowledgement运行在producer的IO线程中，因此不要在该方法中放入很重的逻辑，否则会拖慢producer的消息发送效率。</span><br></pre></td></tr></table></figure>
</li>
<li><p>close</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">关闭interceptor，主要用于执行一些资源清理工作</span><br><span class="line">如前所述，interceptor可能被运行在多个线程中，因此在具体实现时用户需要自行确保线程安全。另外倘若指定了多个interceptor，则producer将按照指定顺序调用它们，并仅仅是捕获每个interceptor可能抛出的异常记录到错误日志中而非在向上传递。这在使用过程中要特别留意。</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="拦截器案例"><a href="#拦截器案例" class="headerlink" title="拦截器案例"></a>拦截器案例</h4><h5 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h5><p>实现一个简单的双interceptor组成的拦截链。第一个interceptor会在消息发送前将时间戳信息加到消息value的最前部；第二个interceptor会在消息发送后更新成功发送消息数或失败发送消息数。</p>
<p><img src="http://p.caigoubao.cc/606599/%E5%A4%A7%E6%95%B0%E6%8D%AE/kafka/8_132256059758060000.png" alt="image"></p>
<h5 id="案例实操"><a href="#案例实操" class="headerlink" title="案例实操"></a>案例实操</h5><h6 id="增加时间戳拦截器"><a href="#增加时间戳拦截器" class="headerlink" title="增加时间戳拦截器"></a>增加时间戳拦截器</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">package com.rickyin.kafka.interceptor;</span><br><span class="line"></span><br><span class="line">import org.apache.kafka.clients.producer.ProducerInterceptor;</span><br><span class="line">import org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line">import org.apache.kafka.clients.producer.RecordMetadata;</span><br><span class="line"></span><br><span class="line">import java.util.Map;</span><br><span class="line"></span><br><span class="line">public class TimerInterceptor implements ProducerInterceptor&lt;String, String&gt; &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; producerRecord) &#123;</span><br><span class="line">        return new ProducerRecord&lt;&gt;(producerRecord.topic(),</span><br><span class="line">                producerRecord.partition(),</span><br><span class="line">                producerRecord.timestamp(),</span><br><span class="line">                producerRecord.key(),</span><br><span class="line">                System.currentTimeMillis() + producerRecord.value(),</span><br><span class="line">                producerRecord.headers());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void onAcknowledgement(RecordMetadata recordMetadata, Exception e) &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void close() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void configure(Map&lt;String, ?&gt; map) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h6 id="统计发送消息成功和发送失败消息数，并在producer关闭时打印这两个计数器"><a href="#统计发送消息成功和发送失败消息数，并在producer关闭时打印这两个计数器" class="headerlink" title="统计发送消息成功和发送失败消息数，并在producer关闭时打印这两个计数器"></a>统计发送消息成功和发送失败消息数，并在producer关闭时打印这两个计数器</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">package com.rickyin.kafka.interceptor;</span><br><span class="line"></span><br><span class="line">import org.apache.kafka.clients.producer.ProducerInterceptor;</span><br><span class="line">import org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line">import org.apache.kafka.clients.producer.RecordMetadata;</span><br><span class="line"></span><br><span class="line">import java.util.Map;</span><br><span class="line"></span><br><span class="line">public class CounterInterceptor implements ProducerInterceptor&lt;String, String&gt; &#123;</span><br><span class="line"></span><br><span class="line">    private long successNum = 0;</span><br><span class="line">    private long errorNum = 0;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; producerRecord) &#123;</span><br><span class="line">        return producerRecord;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void onAcknowledgement(RecordMetadata recordMetadata, Exception e) &#123;</span><br><span class="line">        if (e == null) &#123;</span><br><span class="line">            successNum++;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            errorNum++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 注意：生产者调用close方法之后才会调用到拦截器的这个方法</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public void close() &#123;</span><br><span class="line">        System.out.println(&quot;successNum:&quot; + successNum);</span><br><span class="line">        System.out.println(&quot;errorNum:&quot; + errorNum);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void configure(Map&lt;String, ?&gt; map) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h6 id="producer主程序"><a href="#producer主程序" class="headerlink" title="producer主程序"></a>producer主程序</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">package com.rickyin.kafka.producer;</span><br><span class="line"></span><br><span class="line">import org.apache.kafka.clients.producer.*;</span><br><span class="line">import org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.Arrays;</span><br><span class="line">import java.util.List;</span><br><span class="line">import java.util.Properties;</span><br><span class="line"></span><br><span class="line">public class CustomProducer &#123;</span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        Properties properties = new Properties();</span><br><span class="line">        //设置brokeList（回顾命令行）</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;hadoop102:9092&quot;);</span><br><span class="line">        //设置key和value的序列化</span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        //设置ack</span><br><span class="line">        properties.put(ProducerConfig.ACKS_CONFIG, &quot;all&quot;);</span><br><span class="line">        //设置一次读取多少数据（一批一批的数据）</span><br><span class="line">        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);</span><br><span class="line">        //设置1ms</span><br><span class="line">        properties.put(ProducerConfig.LINGER_MS_CONFIG, 1);</span><br><span class="line"></span><br><span class="line">        List&lt;String&gt; interceptors = new ArrayList();</span><br><span class="line">        interceptors.add(&quot;com.rickyin.kafka.interceptor.CounterInterceptor&quot;);</span><br><span class="line">        interceptors.add(&quot;com.rickyin.kafka.interceptor.TimerInterceptor&quot;);</span><br><span class="line">        </span><br><span class="line">        //指定拦截器：可以指定全类名用逗号隔开，也可以使用list</span><br><span class="line">        properties.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);</span><br><span class="line"></span><br><span class="line">        //1.创建一个生产者对象</span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        //2.调用send方法</span><br><span class="line">        for (int i = 0; i &lt; 1000; i++) &#123;</span><br><span class="line">            Thread.sleep(10);</span><br><span class="line">            producer.send(new ProducerRecord&lt;String, String&gt;(&quot;number&quot;, i + &quot;&quot;, &quot;message-&quot; + i));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        //3.关闭生产者</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Flume对接Kafka"><a href="#Flume对接Kafka" class="headerlink" title="Flume对接Kafka"></a>Flume对接Kafka</h2><h3 id="配置flume-flume-kafka-conf"><a href="#配置flume-flume-kafka-conf" class="headerlink" title="配置flume(flume-kafka.conf)"></a>配置flume(flume-kafka.conf)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># define</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># source</span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line">a1.sources.r1.command = tail -F -c +0 /opt/module/datas/flume.log</span><br><span class="line">a1.sources.r1.shell = /bin/bash -c</span><br><span class="line"></span><br><span class="line"># sink</span><br><span class="line">a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink</span><br><span class="line">a1.sinks.k1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092</span><br><span class="line">a1.sinks.k1.kafka.topic = first</span><br><span class="line">a1.sinks.k1.kafka.flumeBatchSize = 20</span><br><span class="line">a1.sinks.k1.kafka.producer.acks = 1</span><br><span class="line">a1.sinks.k1.kafka.producer.linger.ms = 1</span><br><span class="line"></span><br><span class="line"># channel</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># bind</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
<h3 id="启动kafkaIDEA消费者"><a href="#启动kafkaIDEA消费者" class="headerlink" title="启动kafkaIDEA消费者"></a>启动kafkaIDEA消费者</h3><h3 id="进入flume根目录下，启动flume"><a href="#进入flume根目录下，启动flume" class="headerlink" title="进入flume根目录下，启动flume"></a>进入flume根目录下，启动flume</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/flume-ng agent -c conf/ -n a1 -f jobs/flume-kafka.conf</span><br></pre></td></tr></table></figure>
<h3 id="向-opt-module-datas-flume-log里追加数据，查看kafka消费者消费情况"><a href="#向-opt-module-datas-flume-log里追加数据，查看kafka消费者消费情况" class="headerlink" title="向 /opt/module/datas/flume.log里追加数据，查看kafka消费者消费情况"></a>向 /opt/module/datas/flume.log里追加数据，查看kafka消费者消费情况</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ echo hello &gt;&gt; /opt/module/datas/flume.log</span><br></pre></td></tr></table></figure>
<h2 id="Kafka监控"><a href="#Kafka监控" class="headerlink" title="Kafka监控"></a>Kafka监控</h2><h3 id="Kafka-Monitor"><a href="#Kafka-Monitor" class="headerlink" title="Kafka Monitor"></a>Kafka Monitor</h3><ol>
<li>上传jar包KafkaOffsetMonitor-assembly-0.4.6.jar到集群</li>
<li>在/opt/module/下创建kafka-offset-console文件夹</li>
<li>将上传的jar包放入刚创建的目录下</li>
<li><p>在/opt/module/kafka-offset-console目录下创建启动脚本start.sh，内容如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">java -cp KafkaOffsetMonitor-assembly-0.4.6-SNAPSHOT.jar \</span><br><span class="line">com.quantifind.kafka.offsetapp.OffsetGetterWeb \</span><br><span class="line">--offsetStorage kafka \</span><br><span class="line">--kafkaBrokers hadoop102:9092,hadoop103:9092,hadoop104:9092 \</span><br><span class="line">--kafkaSecurityProtocol PLAINTEXT \</span><br><span class="line">--zk hadoop102:2181,hadoop103:2181,hadoop104:2181 \</span><br><span class="line">--port 8086 \</span><br><span class="line">--refresh 10.seconds \</span><br><span class="line">--retain 2.days \</span><br><span class="line">--dbName offsetapp_kafka &amp;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在/opt/module/kafka-offset-console目录下创建mobile-logs文件夹</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /opt/module/kafka-offset-console/mobile-logs</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动KafkaMonitor</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>登录页面hadoop102:8086端口查看详情</p>
</li>
</ol>
<h3 id="Kafka-Manager"><a href="#Kafka-Manager" class="headerlink" title="Kafka Manager"></a>Kafka Manager</h3><ol>
<li>上传压缩包kafka-manager-1.3.3.15.zip到集群</li>
<li>解压到/opt/module</li>
<li><p>修改配置文件conf/application.conf</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kafka-manager.zkhosts=&quot;kafka-manager-zookeeper:2181&quot;</span><br><span class="line">修改为：</span><br><span class="line">kafka-manager.zkhosts=&quot;hadoop102:2181,hadoop103:2181,hadoop104:2181&quot;</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动kafka-manager</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-manager</span><br></pre></td></tr></table></figure>
</li>
<li><p>登录hadoop102:9000页面查看详细信息</p>
</li>
</ol>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/02/05/kafka基础学习-二之架构深入/" rel="next" title="kafka基础学习-二之架构深入">
                <i class="fa fa-chevron-left"></i> kafka基础学习-二之架构深入
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/02/12/HBase基础学习-一之简介、安装、shell操作/" rel="prev" title="HBase基础学习-一之简介、安装、shell操作">
                HBase基础学习-一之简介、安装、shell操作 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/We.jpg"
                alt="RickYinPeng" />
            
              <p class="site-author-name" itemprop="name">RickYinPeng</p>
              <p class="site-description motion-element" itemprop="description">毕生追求无他，爱与自由而已。</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">116</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/RickYinPeng" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-globe"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://weibo.com/u/1041120045?is_hot=1" target="_blank" title="Weibo">
                      
                        <i class="fa fa-fw fa-globe"></i>Weibo</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-API"><span class="nav-number">1.</span> <span class="nav-text">Kafka API</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Producer-API"><span class="nav-number">1.1.</span> <span class="nav-text">Producer API</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#消息发送流程"><span class="nav-number">1.1.1.</span> <span class="nav-text">消息发送流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#异步发送API"><span class="nav-number">1.1.2.</span> <span class="nav-text">异步发送API</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#导入依赖"><span class="nav-number">1.1.2.1.</span> <span class="nav-text">导入依赖</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#编写代码"><span class="nav-number">1.1.2.2.</span> <span class="nav-text">编写代码</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#不带回调函数的API"><span class="nav-number">1.1.2.2.1.</span> <span class="nav-text">不带回调函数的API</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#带回调函数的API"><span class="nav-number">1.1.2.2.2.</span> <span class="nav-text">带回调函数的API</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#同步发送API"><span class="nav-number">1.1.3.</span> <span class="nav-text">同步发送API</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Consumer-API"><span class="nav-number">1.2.</span> <span class="nav-text">Consumer API</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#手动提交offset"><span class="nav-number">1.2.1.</span> <span class="nav-text">手动提交offset</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#导入依赖-1"><span class="nav-number">1.2.1.1.</span> <span class="nav-text">导入依赖</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#编写代码-1"><span class="nav-number">1.2.1.2.</span> <span class="nav-text">编写代码</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#代码分析"><span class="nav-number">1.2.1.3.</span> <span class="nav-text">代码分析</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#数据重复消费问题"><span class="nav-number">1.2.1.4.</span> <span class="nav-text">数据重复消费问题</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#自动提交offset"><span class="nav-number">1.2.2.</span> <span class="nav-text">自动提交offset</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自定义Interceptor"><span class="nav-number">1.3.</span> <span class="nav-text">自定义Interceptor</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#拦截器原理"><span class="nav-number">1.3.1.</span> <span class="nav-text">拦截器原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#拦截器案例"><span class="nav-number">1.3.2.</span> <span class="nav-text">拦截器案例</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#需求"><span class="nav-number">1.3.2.1.</span> <span class="nav-text">需求</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#案例实操"><span class="nav-number">1.3.2.2.</span> <span class="nav-text">案例实操</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#增加时间戳拦截器"><span class="nav-number">1.3.2.2.1.</span> <span class="nav-text">增加时间戳拦截器</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#统计发送消息成功和发送失败消息数，并在producer关闭时打印这两个计数器"><span class="nav-number">1.3.2.2.2.</span> <span class="nav-text">统计发送消息成功和发送失败消息数，并在producer关闭时打印这两个计数器</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#producer主程序"><span class="nav-number">1.3.2.2.3.</span> <span class="nav-text">producer主程序</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Flume对接Kafka"><span class="nav-number">2.</span> <span class="nav-text">Flume对接Kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#配置flume-flume-kafka-conf"><span class="nav-number">2.1.</span> <span class="nav-text">配置flume(flume-kafka.conf)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动kafkaIDEA消费者"><span class="nav-number">2.2.</span> <span class="nav-text">启动kafkaIDEA消费者</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#进入flume根目录下，启动flume"><span class="nav-number">2.3.</span> <span class="nav-text">进入flume根目录下，启动flume</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#向-opt-module-datas-flume-log里追加数据，查看kafka消费者消费情况"><span class="nav-number">2.4.</span> <span class="nav-text">向 /opt/module/datas/flume.log里追加数据，查看kafka消费者消费情况</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka监控"><span class="nav-number">3.</span> <span class="nav-text">Kafka监控</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-Monitor"><span class="nav-number">3.1.</span> <span class="nav-text">Kafka Monitor</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-Manager"><span class="nav-number">3.2.</span> <span class="nav-text">Kafka Manager</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        ﻿<div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">RickYinPeng</span>

  
</div>
<div class="powered-by">
<i class="fa fa-user-md"></i>
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量：<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客：<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>




  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
